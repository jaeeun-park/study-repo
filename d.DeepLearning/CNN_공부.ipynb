{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_공부.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SSmfhLTFG5O",
        "colab_type": "text"
      },
      "source": [
        "####  pyTorch를 비롯해  필요한 라이브러리를 읽어온다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UHNOTSbDdQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as vision_dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "from torch.utils import data\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPDsxxUWE7S0",
        "colab_type": "text"
      },
      "source": [
        "### Hyper-parameter 세팅 및 기타 변수 지정\n",
        "1. gpu에서 사용하기 위해 cuda 설정하여 device에 저장\n",
        "2. parameter 설정하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4gqqBfgF3wm",
        "colab_type": "text"
      },
      "source": [
        "gpu(cuda)가 사용 가능한지 확인하는 메서드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVj1DkoHFXGV",
        "colab_type": "code",
        "outputId": "4c6fecdc-1091-4e41-850a-dd6a6d8ccfb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkkpjVy1GK20",
        "colab_type": "text"
      },
      "source": [
        "사용할 device를 device 변수에 저장해놓기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUMxUSDvF2Cg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUO0LNUTGk6E",
        "colab_type": "text"
      },
      "source": [
        "lr  = learning rate : back propagation 할 때 cost function 에서 최적점 찾아갈 때 사용 경험상 0.001정도가 적당하다.\n",
        "- 너무 크면 발산한다.\n",
        "- 작으면 너무 오래 걸리는 문제가 발생한다.\n",
        "\n",
        "batch_size : 벡터 하나씩 넣으면 너무 오래 걸리므로 batch_size를 정해서 여러개 벡터를 한 번에 넣어준다.\n",
        "\n",
        "best_acc = best test accuracy : 가장 좋은 정확도\n",
        "\n",
        "start_epoch = 0 : 시작 epoch 맨 처음은 0 check point있다면 check point부터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdYE2tBAGPZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.001 # learning rate\n",
        "batch_size = 128 # batch_size : 벡터 하나씩 넣으면 너무\n",
        "best_acc = 0\n",
        "start_epoch = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG_L4tDQHXve",
        "colab_type": "text"
      },
      "source": [
        "### 다양한 함수 연습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYxi5ZbMHWlS",
        "colab_type": "code",
        "outputId": "b2f65ed2-5579-4058-90f4-a0db60d22333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# torch.view 연습\n",
        "\n",
        "sample = torch.randn(2000, 3, 64, 64) # batch, chanel, height, width\n",
        "\n",
        "B, C, H, W = sample.size() # torch의 size()는 torch의 모양을 돌려준다.\n",
        "\n",
        "sample1 = sample.view(B,-1) # (2000, 3*64*64) flat한 vector로 만들어주기\n",
        "\n",
        "print(sample1.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2000, 12288])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwoOGiWnMfiN",
        "colab_type": "text"
      },
      "source": [
        "위 sample1을 (2000\\*3, 64\\*64) 로 바꿔보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a6stc99MRDY",
        "colab_type": "code",
        "outputId": "840e1eae-b6ef-447d-8fdc-0073baefd6af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "sample2 = sample1.view(B*C, -1)\n",
        "print(sample2.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6000, 4096])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEGZFzlCMyLC",
        "colab_type": "text"
      },
      "source": [
        "torch.view 연습 예제\n",
        "- FloatTensor(a,b,c) : tensor는 기본적으로 3차원을 말한다. FloatTensor는 dtype이 float인 cpu tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqg7opPLMwNv",
        "colab_type": "code",
        "outputId": "e0996bae-5ea3-41b2-938e-3f9824c2870a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "a = torch.FloatTensor(5, 20, 100)\n",
        "a1 = a.view(2, 10, -1)\n",
        "print(a1.size())\n",
        "a2 = a.view(-1, 10, 200)\n",
        "print(a2.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 10, 500])\n",
            "torch.Size([5, 10, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzI3zXZQN9bU",
        "colab_type": "text"
      },
      "source": [
        "dimension 간의 사이즈 이동이 가능하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWnBzrHcM3Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = torch.randn(2000, 3, 32, 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ1rLoIyOGSz",
        "colab_type": "text"
      },
      "source": [
        "0, 1, 2, 3 -> 0, 1, 3, 2 -> 2와 3의 위치를 바꾸고 싶을 때 다음 permute 메서드를 사용하여 바꿀 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qESpuKn_OFxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = sample.permute(0,1,3,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxHJgE8ROWBI",
        "colab_type": "code",
        "outputId": "36904e3f-6870-40fe-b37d-5adeeed535b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(sample.size())\n",
        "print(sample1.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2000, 3, 32, 64])\n",
            "torch.Size([2000, 3, 64, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuk3ow2FOhT9",
        "colab_type": "text"
      },
      "source": [
        "sample1의 dimension을 원래대로 돌리고 싶다면?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK4hVVgfOe6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = sample1.permute(0,1,3,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT9sprGzOpW3",
        "colab_type": "code",
        "outputId": "7fb578d4-2403-4f71-d0ac-c9de0f030d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# torch.equal은 torch의 size가 같고 element가 같으면 True를 반환\n",
        "# 그 이외의 것들은 모두 False\n",
        "print(torch.equal(sample, sample2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zaM1pJAOsi5",
        "colab_type": "text"
      },
      "source": [
        "### Convolution layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk1CSegFPVK8",
        "colab_type": "text"
      },
      "source": [
        "torch.nn.conv 연습하기\n",
        "- nn.Conv2d(in, out, filter_size, stride, padding)\n",
        "- output size가 (16, 128, 32, 32)가 되도록 해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVIAJSZiPOGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input1 = torch.zeros(16, 3, 64, 64) # input으로 들어갈 torch.Tensor\n",
        "conv1 = nn.Conv2d(3, 512, 3, 1, 1) # 16,3,64,64 -> 16, 512, 64, 64 \n",
        "conv2 = nn.Conv2d(512, 128, 4, 2, 1)# 16, 512, 64, 64 -> 16, 128, 32, 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUks4y-1Px0i",
        "colab_type": "code",
        "outputId": "31c62310-125f-4326-ac5f-b5f269570a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "out = conv1(input1)\n",
        "print(out.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgaD-iRcTjA7",
        "colab_type": "code",
        "outputId": "315edd3f-6b3e-4a31-e5e2-6a24958a5852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "output = conv2(out)\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 128, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnFUBvOZUYQp",
        "colab_type": "text"
      },
      "source": [
        "torch.nn.conv 연습2\n",
        "- nn.Conv2d(in, out, filter_size, stride, padding)\n",
        "- output size가 (16, 512, 16, 16)이 되도록 해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqMZt_PnToka",
        "colab_type": "code",
        "outputId": "0ad087a6-c59e-45bc-f019-06769b72445c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "input2 = torch.zeros(16,3,64,64)\n",
        "conv1 = nn.Conv2d(3, 64, 3, 1, 1) # 16,3,64,64 -> 16,64,64,64\n",
        "conv2 = nn.Conv2d(64, 512, 3, 4, 1) # 16,64,32,32 -> 16,512,16,16\n",
        "\n",
        "out = conv1(input2)\n",
        "output = conv2(out)\n",
        "\n",
        "print(out.size())\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 64, 64, 64])\n",
            "torch.Size([16, 512, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjDPLehiVgRe",
        "colab_type": "text"
      },
      "source": [
        "torch.nn.conv 연습3\n",
        "- nn.Conv2d(in, out, filter_size, stride, padding)\n",
        "- output size가 (16, 512, 64, 64)이 되도록 해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOZcjEbWVJHT",
        "colab_type": "code",
        "outputId": "4601f35c-67a8-47cf-bad9-379ba6183a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "input3 = torch.zeros(16, 3, 64, 64)\n",
        "conv1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
        "conv2 = nn.Conv2d(64, 512, 3, 1, 1)\n",
        "\n",
        "out = conv1(input3)\n",
        "output = conv2(out)\n",
        "\n",
        "print(out.size())\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 64, 64, 64])\n",
            "torch.Size([16, 512, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dIAljckWWq0",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 로딩\n",
        "#### 연습 데이터를 불러와서 전처리를 거쳐 학습 시켜봅시다.\n",
        "\n",
        "> Data Augmentation은 CNN의 성능을 향상시키기 위해 사용하는 기법이다. 이미지를 여러 방법을 통해 변형 시켜서 입력 이미지로 사용하는 방식이다. 이와 같은 방법을 사용하는 이유는 모든 픽셀을 1칸씩 이동 시켰을 때 사람은 똑같이 인식하지만 컴퓨터 입장에서는 원본 이미지와 다른 것으로 인식하게 된다. 이를 해결하기 위해 data augmentation을 사용한다. 다시말해 이미지 레이블을 변경하지 않고 픽셀을 변화시키는 방법이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAc1AcwVjFH1",
        "colab_type": "text"
      },
      "source": [
        "트레인셋 전처리 transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh7KWtFcWP2J",
        "colab_type": "code",
        "outputId": "5628ab9e-5f71-4f17-92cf-2fb4419f69bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print('==> Preparing data...')\n",
        "\n",
        "transform_train = transforms.Compose([ # 여러개의 transforms를 조립 list형으로 transform 전달 \n",
        "    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을줘서 32x32로 random cropping(랜덤으로 자르기?)\n",
        "    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지를 반전하여 넣어준다.\n",
        "    transforms.ToTensor(),\n",
        "    # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LtW6_rVcGEa",
        "colab_type": "text"
      },
      "source": [
        "랜덤 cropping을 하고 이미지 좌우 반전을 해주는 이유는??? ex) 고양이\n",
        "![대체 텍스트](https://t1.daumcdn.net/cfile/tistory/99F718445B62CED001)\n",
        "- 좌우 반전을 시키는 이유는 왼쪽을 바라보는 고양이만 넣어주게되면  오른쪽을 바라보는 고양이를 못 맞추게 된다. 좌우 반전된 사진을 섞어서 인풋으로 넣어주면 고양이가 어느쪽을 바라보더라도 맞추게 된다.\n",
        "\n",
        "![대체 텍스트](https://t1.daumcdn.net/cfile/tistory/9959F23A5B62CED111)\n",
        "- 이미지를 잘라주는 이유는 고양이가 상자 속에 들어가서 꼬리만 있는 사진을 사람은 꼬리를 보고 고양이라고 판단할 수 있으나 딥러닝은 상자까지 인식해서 고양이의 특징을 제대로 파악 못한다. 사람이 인식하는 방법을 모방하기 위해 부분부분 잘라서 넣어주면 각 부분만 보고도 고양이라고 반단할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCFVX28mfTKY",
        "colab_type": "text"
      },
      "source": [
        "테스트 데이터 전처리 transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zCfzKEwcFSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni69ohNtfXs0",
        "colab_type": "text"
      },
      "source": [
        "#### 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZXQjVjZfWtD",
        "colab_type": "code",
        "outputId": "d46d5f17-4715-4e7d-eddc-212252d12f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# torchvision.datasets.CIFAR10: CIFAR10 데이터셋 불러오기\n",
        "# root : 데이터 셋이 있는 경로, train=True : trainset으로 불러오기 Fasle면 test set\n",
        "# download: True면 dataset을 인터넷에서 받아와서 경로에 넣어준다.\n",
        "# transform: transform/function을 넣어주면 이미지를 이에 따라 변환시켜준다.\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "# python iterable로 만들어주는애 = torch.utils.data.DataLoader\n",
        "# shuffle=True : 매 epoch마다 reshuffle한다.\n",
        "# num_workers는 데이터 로딩에 사용되는 subprocess 개수를 정해주는 애 \n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1) \n",
        "print(trainloader.dataset.data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y878Y0blic53",
        "colab_type": "code",
        "outputId": "59e47155-22dd-48f1-c02e-99e4b03e109f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False,num_workers=1 )\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZR6TZ7vjNxw",
        "colab_type": "text"
      },
      "source": [
        "#### 이미지 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPBP2i8Ti7zO",
        "colab_type": "code",
        "outputId": "1b5e8dd8-4d69-4766-f934-2679dbb698b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "def showImages(image, row):\n",
        "    for _ in range(row):\n",
        "        idx = np.random.choice(batch_size, 6) # 0 ~ 127의 정수 중 6개를 임의로 선택\n",
        "        images = image.numpy()[idx].transpose(0,2,3,1).clip(0,1) # 선택된 indexㅇ 해당하는 이미지를 가져온다.\n",
        "        plt.figure(figsize=(15,90)) # 세로 길이 15, 가로길이 15 * 6 의 화면 생성\n",
        "        \n",
        "        # 1줄에 6개 보여주니까 6개 출력\n",
        "        for i in range(161, 167):\n",
        "            plt.subplot(i)\n",
        "            plt.imshow(images[i - 161])\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            \n",
        "        plt.show() # 1줄 보여주기\n",
        "        \n",
        "for i, (image, labels) in enumerate(trainloader):\n",
        "    showImages(image.squeeze(), 3)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x6480 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 1080x6480 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x6480 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkL2bk7Qlc41",
        "colab_type": "code",
        "outputId": "c8882656-82b5-4304-e1c1-8a7ac52ad842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# 미니 배치가 몇개가 있는지\n",
        "print('[info] # of train batch :', len(trainloader)) \n",
        "print('[info] # of test batch: ', len(testloader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[info] # of train batch : 391\n",
            "[info] # of test batch:  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSgbotUdpnPi",
        "colab_type": "text"
      },
      "source": [
        "### 학습 신경망 구현\n",
        "\n",
        "net, optimizer, trainloader, epochs\n",
        "\n",
        "epochs : 학습 반복 횟수\n",
        "\n",
        "optimizer : 최적화 방법\n",
        "\n",
        "trainloader : 학습 데이터\n",
        "\n",
        "net: 뉴럴 넷"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K2tu6JRou9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network(net, optimizer, trainloader, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        running_loss = 0.0 # running_loss : target과 label의 score들의 합\n",
        "        for i, data in enumerate(trainloader):\n",
        "            inputs, labels = data\n",
        "            \n",
        "            # gpu로 올려서 학습 진행한다.\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # 현재의 backprop을 계산하기 위해서 저장했던 activation buffer를 비워준다.\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # input을 network에 넣어서 결과를 얻어낸다.\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            # loss function에 주어진 target과 labels를 넣으면 score를\n",
        "            # 계산하여 반환\n",
        "            # 여기서 criterion은 CrossEntropyLoss가 사용되었음.\n",
        "            # 후에 정의함 왜 후에 정의하는지는 모르겠음.\n",
        "            # criterion(input, target)\n",
        "            loss = criterion(outputs, labels) \n",
        "            \n",
        "            # 주어진 loss 값을 바탕으로 backpropagation이 진행된다.\n",
        "            # sum of gradients of given tensors w.r.t graph leaves\n",
        "            loss.backward()\n",
        "            \n",
        "            # 계산된 Backprop을 바탕으로 gradient descending을 수행한다.\n",
        "            # 파라미터를 업데이트 시켜준다.\n",
        "            optimizer.step() \n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            # print every 500 mini-batches\n",
        "            if (i+1) % 100 == 0:\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                     (epoch+1, i+1, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "    \n",
        "    print('Finished Training')\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4gY7xQ3zVsT",
        "colab_type": "text"
      },
      "source": [
        "테스트를 실행하는 함수 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk-YaKe9wHfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader):\n",
        "    # 학습을 시키지 않는 테스트 모드로 사용하겠다고 선언한 것\n",
        "    # Dropout, BatchNorm등 train모드가 아니고 eval모드로 작동. \n",
        "    model.eval()\n",
        "    test_loss = 0 # 테스트의 loss값\n",
        "    correct = 0 # 정확도\n",
        "    \n",
        "    for data, target in test_loader:\n",
        "        # gpu로 이동해서 작업한다.\n",
        "        data = data.to(device) \n",
        "        target = target.to(device)\n",
        "        \n",
        "        # 학습된 모델에 테스트 데이터를 넣는다.\n",
        "        output = model(data)\n",
        "        \n",
        "        #결과의 예측 결과중 가장 높은 확률인것을 받는다.\n",
        "        # output은 10개 클래드들에 대해 energies를 반환하기 때문에\n",
        "        # 그 중에서 가장 높은 값이 제일 정확하므로 max를 사용한다.\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        \n",
        "        # target과 같은 pred의 예측결과 값들을 합한다.\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        \n",
        "    # ?????\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(\"test_loss:\", test_loss)\n",
        "    print(\"\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
        "        correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2b1XS0PzZFi",
        "colab_type": "text"
      },
      "source": [
        "모델 파라미터 개수를 리턴하는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5itH_bBzAWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    print('model.parameters() = ', model.parameters())\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arsYgLQ8036h",
        "colab_type": "text"
      },
      "source": [
        "### MNIST에 사용한 MLP를 적용\n",
        "\n",
        "nuralnetwork는 꼭 torch.nn.Module을 상속시켜준다.\n",
        "\n",
        "\\_\\_init__, forward를 오버라이딩 해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sq4oivCzmd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module): \n",
        "    def __init__(self):\n",
        "        # 파이썬 문법상 해줘야한다.\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        \n",
        "        # layer들은 순서가 중요하므로 sequential 인 list에다가 순서대로 저장한다.\n",
        "        layer_list = [] \n",
        "        # 들어오는 학습 데이터가 transform에 의하여 32*32사이즈로 들어오므로 크기를 맞춰준다.\n",
        "        layer_list.append(nn.Linear(3*32*32, 256))\n",
        "        \n",
        "        # spatial을 다 없애서 1d를 사용한다.\n",
        "        # BatchNorm을 해주는 이유\n",
        "        # -> regularization(정규화)을 해줘서 학습의 효율을 높여준다.\n",
        "        #    학습 속도가 개선되고, 가중치 초기값 선택의 의존성이 적어진다.\n",
        "        #    overfitting의 이험을 줄일 수 있다\n",
        "        #    Gradient Vanishing 문제(기울기값이 0이되는 문제)를 해결할 수 있다.\n",
        "        layer_list.append(nn.BatchNorm1d(256))\n",
        "        layer_list.append(nn.ReLU())\n",
        "        \n",
        "        #Layer2\n",
        "        layer_list.append(nn.Linear(256, 64))\n",
        "        layer_list.append(nn.BatchNorm1d(64))\n",
        "        layer_list.append(nn.ReLU())\n",
        "        \n",
        "        #Layer3\n",
        "        layer_list.append(nn.Linear(64, 10))\n",
        "        \n",
        "        # nn.Sequential에 layer_list를 넘겨준다.\n",
        "        self.net = nn.Sequential(*layer_list)\n",
        "        \n",
        "       \n",
        "    def forward(self, x):\n",
        "        # 기존의 128(B), 3(C), 32(H), 32(W) 를 일자로 쭉 늘려준다.\n",
        "        x = x.view(-1, 32*32*3) \n",
        "        x = self.net(x) # net에 넣어주면 계산\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFCoBSPyEpxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 뉴럴 네트워크를 인스턴스화 해서 빠른 학습을 위해 gpu에 올려준다.\n",
        "mnist_net = MNIST_Net().to(device)\n",
        "# loss function을 정의해준다. cross entrophy loss 사용\n",
        "# continuous한 값에는 MSE, L1, L2 loss function을 사용하는 것이 좋다.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer 정의\n",
        "# training할 파라미터와 learning rate를 인자로 준다.\n",
        "# Adam(A Method for Stochastic Optimization) stochastic -> 모집단에서 임의로 추출한 표본에 따라 모집단의 상태를 추측\n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uJsRCIzFOCm",
        "colab_type": "code",
        "outputId": "cb0ce554-e533-4108-85bc-9169ad2c52f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "train_network(mnist_net, optimizer, trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 2.020\n",
            "[1,   200] loss: 1.828\n",
            "[1,   300] loss: 1.739\n",
            "[2,   100] loss: 1.656\n",
            "[2,   200] loss: 1.629\n",
            "[2,   300] loss: 1.602\n",
            "[3,   100] loss: 1.556\n",
            "[3,   200] loss: 1.562\n",
            "[3,   300] loss: 1.545\n",
            "[4,   100] loss: 1.518\n",
            "[4,   200] loss: 1.509\n",
            "[4,   300] loss: 1.501\n",
            "[5,   100] loss: 1.486\n",
            "[5,   200] loss: 1.485\n",
            "[5,   300] loss: 1.468\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNxNemWSGe8w",
        "colab_type": "code",
        "outputId": "d8ac805c-0e77-40e4-c1e7-f5ecfbd7acae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test(mnist_net, testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: 0.0\n",
            "\n",
            "Test set: Accuracy: 5018/10000 (50%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsujKutxHTLr",
        "colab_type": "text"
      },
      "source": [
        "## 심플한 CNN 모델 만들기\n",
        "<구성>\n",
        "\n",
        "Layer 1 - input: 3 x 32 x 32, output: 64 x 32 x 32- ReLU + BatchNorm\n",
        "\n",
        "Layer 2 - input: 64 x 32 x 32, output: 128 x 16 x 16- ReLU + BatchNorm (Down Conv라고 부릅니다.)\n",
        "\n",
        "Layer 5 - Global Average Pooling (128 x 16 x 16 => 128 x 1 x 1)\n",
        "\n",
        "Layer 6 - input: 128 x 1 x 1, output 10 x 1 x 1 - ReLU + BatchNorm\n",
        "\n",
        "![대체 텍스트](https://cdn-images-1.medium.com/max/1600/1*D47ER7IArwPv69k3O_1nqQ.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSD9jqp1GxFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiyCNN, self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        \n",
        "        # Layer1\n",
        "        # (128, 3, 32, 32) -> (128, 64, 32, 32)\n",
        "        # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
        "        # F = 3 p = 1\n",
        "        # F = 5 p = 2\n",
        "        # F = 7 p = 3\n",
        "        layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)]\n",
        "        # 앞선 MLP 시간과 달리 spatial resolution(공간 해상도)이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
        "        layers += [nn.BatchNorm2d(64)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        # Layer2\n",
        "        # (128, 64, 32, 32) => (128, 128, 16, 16)\n",
        "        layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
        "        layers += [nn.BatchNorm2d(128)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        # Layer3\n",
        "        # (B, 128, 16, 16) => (B, 256, 8, 8)\n",
        "        layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
        "        layers += [nn.BatchNorm2d(256)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        # Layer4\n",
        "        # (B, 256, 8, 8) => (B, 512, 4, 4)\n",
        "        layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
        "        layers += [nn.BatchNorm2d(512)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        #Layer 5 \n",
        "        # Global Average Pooling (128 x 16 x 16 => 128 x 1 x 1)\n",
        "        layers += [nn.AdaptiveAvgPool2d(1)] # 1 -> (-1,1) -> (512, 1) \n",
        "\n",
        "        # Layer 6 \n",
        "        # input: 128 x 1 x 1, output 10 x 1 x 1 - ReLU + BatchNorm\n",
        "        layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n",
        "        \n",
        "        \n",
        "        self.main = nn.Sequential(*layers)\n",
        "       \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.main(x)\n",
        "        return out.squeeze(3).squeeze(2)\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jfRX_TfPwOz",
        "colab_type": "code",
        "outputId": "abdacc54-8658-4b8d-a4cd-c5ed5e2c5284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "cifar_net = DiyCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr)\n",
        "\n",
        "print('[info] number of model parameter - %d' %(count_parameters(cifar_net)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.parameters() =  <generator object Module.parameters at 0x7fe7dacc7ba0>\n",
            "[info] number of model parameter - 1558026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1y6HmbKP06A",
        "colab_type": "code",
        "outputId": "b77c954b-50ba-4c9d-e5b4-8c6bca66cda3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "train_network(cifar_net, optimizer, trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.731\n",
            "[1,   200] loss: 1.476\n",
            "[1,   300] loss: 1.358\n",
            "[2,   100] loss: 1.191\n",
            "[2,   200] loss: 1.143\n",
            "[2,   300] loss: 1.095\n",
            "[3,   100] loss: 1.030\n",
            "[3,   200] loss: 1.003\n",
            "[3,   300] loss: 0.964\n",
            "[4,   100] loss: 0.916\n",
            "[4,   200] loss: 0.913\n",
            "[4,   300] loss: 0.896\n",
            "[5,   100] loss: 0.855\n",
            "[5,   200] loss: 0.824\n",
            "[5,   300] loss: 0.841\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8RBHi5RQ1LT",
        "colab_type": "code",
        "outputId": "0406061f-bc76-488b-803e-0992d71df6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test(cifar_net, testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: 0.0\n",
            "\n",
            "Test set: Accuracy: 7167/10000 (72%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFSZTgs2UOjR",
        "colab_type": "text"
      },
      "source": [
        "### Average Pooling대신 Linear Layer를 사용하여 비교해보자.\n",
        "\n",
        "average pooling parameter개수 = 1,558,026\n",
        "\n",
        "linear layer parameter 개수 = 2,614,794\n",
        "\n",
        "\n",
        "성능은 비슷하다 \n",
        "\n",
        "Linear Layer가 paramter를 많이 차지하므로 더 무겁다.\n",
        "\n",
        "Aveage Pooling이 더 가벼워서 많이 사용한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o22lVxXtRswB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiyCNN, self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        \n",
        "        # Layer1\n",
        "        # (128, 3, 32, 32) -> (128, 64, 32, 32)\n",
        "        layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)]\n",
        "        # 앞선 MLP 시간과 달리 spatial resolution(공간 해상도)이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
        "        layers += [nn.BatchNorm2d(64)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        # Layer2\n",
        "        # (128, 64, 32, 32) => (128, 128, 16, 16)\n",
        "        layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
        "        layers += [nn.BatchNorm2d(128)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        # Layer3\n",
        "        # (B, 128, 16, 16) => (B, 256, 8, 8)\n",
        "        layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
        "        layers += [nn.BatchNorm2d(256)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        # Layer4\n",
        "        # (B, 256, 8, 8) => (B, 512, 4, 4)\n",
        "        layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
        "        layers += [nn.BatchNorm2d(512)]\n",
        "        layers += [nn.ReLU()] # B X 512*4 -> 128 X 512\n",
        "        \n",
        "        # classifier\n",
        "        classifier = []\n",
        "        classifier += [nn.Linear(512*4, 512)]\n",
        "        \n",
        "        classifier += [nn.Linear(512, 10)]\n",
        "        \n",
        "        \n",
        "        self.main = nn.Sequential(*layers)\n",
        "        self.classifier = nn.Sequential(*classifier)\n",
        "       \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.main(x) # 128, 512, 2, 2\n",
        "        out = out.view(out.size(0), -1) # 128, 152*2*2\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n_VwcLzWzAs",
        "colab_type": "code",
        "outputId": "07c36361-cb56-4451-853d-39594226e361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "cifar_net = DiyCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr)\n",
        "\n",
        "print('[info] number of model parameter - %d' % (count_parameters(cifar_net)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.parameters() =  <generator object Module.parameters at 0x7fe7daeb81a8>\n",
            "[info] number of model parameter - 2607114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1Yu_v5hXHwl",
        "colab_type": "code",
        "outputId": "e8634daf-bbca-4188-b4d8-c3f7d03ad933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "train_network(cifar_net, optimizer, trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.745\n",
            "[1,   200] loss: 1.508\n",
            "[1,   300] loss: 1.388\n",
            "[2,   100] loss: 1.217\n",
            "[2,   200] loss: 1.172\n",
            "[2,   300] loss: 1.104\n",
            "[3,   100] loss: 1.023\n",
            "[3,   200] loss: 0.988\n",
            "[3,   300] loss: 0.963\n",
            "[4,   100] loss: 0.911\n",
            "[4,   200] loss: 0.880\n",
            "[4,   300] loss: 0.866\n",
            "[5,   100] loss: 0.799\n",
            "[5,   200] loss: 0.801\n",
            "[5,   300] loss: 0.807\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj_pAkw7YJyn",
        "colab_type": "code",
        "outputId": "5e5ed609-38e2-46d1-abe6-e96a4d992128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test(cifar_net, testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: 0.0\n",
            "\n",
            "Test set: Accuracy: 7457/10000 (75%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YXTeHAqaSvr",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 initialization\n",
        "\n",
        "initialization을 하는 이유는 deep neural network 통해서 forward중에 exploding, vanishing이 일어나는 것을 예방하기 위해서다.\n",
        "\n",
        "exploding or vanishing이 일어나게 되면 backward 과정에서 cost function이 발산하거나 너무 천천히 최적화되거나 local minimum 문제가 발생하게 된다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe2xmbEtY_Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiyCNN, self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        \n",
        "        layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)]\n",
        "        layers += [nn.BatchNorm2d(64)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
        "        layers += [nn.BatchNorm2d(128)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
        "        layers += [nn.BatchNorm2d(256)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
        "        layers += [nn.BatchNorm2d(512)]\n",
        "        layers += [nn.ReLU()]\n",
        "        \n",
        "        layers += [nn.AdaptiveAvgPool2d(1)] # 1 -> (-1,1) -> (512, 1) \n",
        "\n",
        "        layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n",
        "        \n",
        "        \n",
        "        self.main = nn.Sequential(*layers)\n",
        "        self._reset_params() # initialize 하는 부분\n",
        "        \n",
        "    \n",
        "    # 초기 weight 설정\n",
        "    # xavier 초기값 설정\n",
        "    # -> 앞 layer의 입력 노드 수와 출력 노드 수를 고려하여 초기 값을 설정\n",
        "    # a = gain * sqrt(6 / (fan_in + fan_out))\n",
        "    # torch.nn.init.xavier_uniform_(w, gain)\n",
        "    # w : weight n-dimensional torch.Tensor, gain : optional scaling factor\n",
        "    def _reset_params(self):\n",
        "        for i, layer in enumerate(self.main):\n",
        "            if type(layer) == nn.Conv2d:\n",
        "                torch.nn.init.xavier_uniform_(layer.weight.data)\n",
        "       \n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.main(x).squeeze(3).squeeze(2)\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dp6nnIBhRu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_net = DiyCNN().to(device)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSjE5TMnhh1b",
        "colab_type": "code",
        "outputId": "54bb8bb1-8301-4eaf-ea9d-c6840edba69b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "train_network(cifar_net, optimizer, trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.741\n",
            "[1,   200] loss: 1.488\n",
            "[1,   300] loss: 1.368\n",
            "[2,   100] loss: 1.244\n",
            "[2,   200] loss: 1.171\n",
            "[2,   300] loss: 1.119\n",
            "[3,   100] loss: 1.037\n",
            "[3,   200] loss: 1.029\n",
            "[3,   300] loss: 0.988\n",
            "[4,   100] loss: 0.936\n",
            "[4,   200] loss: 0.925\n",
            "[4,   300] loss: 0.919\n",
            "[5,   100] loss: 0.848\n",
            "[5,   200] loss: 0.827\n",
            "[5,   300] loss: 0.831\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLh3hGJXjBv3",
        "colab_type": "code",
        "outputId": "9f53e814-9df7-43bf-bb99-f2c38656e7a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test(cifar_net, testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: 0.0\n",
            "\n",
            "Test set: Accuracy: 7271/10000 (73%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMH8VSbXkYBy",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 전처리 Normalization을 없애면 어떻게 변할까?\n",
        "\n",
        "-> 성능이 떨어진다.\n",
        "> normalization(정규화)를 하지 않으면 outlier 때문에 학습 능력이 떨어지기 때문이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab23JEFHjatG",
        "colab_type": "code",
        "outputId": "2c596d94-a1ff-46f0-a24d-b10b3a594685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print('==> Preparing data...')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_x6Jl2flovv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_net = DiyCNN().to(device)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEiRTxfVl5Lm",
        "colab_type": "code",
        "outputId": "86c22667-6954-47eb-b2fc-4edd06d1f223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "train_network(cifar_net, optimizer, trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.714\n",
            "[1,   200] loss: 1.486\n",
            "[1,   300] loss: 1.403\n",
            "[2,   100] loss: 1.248\n",
            "[2,   200] loss: 1.177\n",
            "[2,   300] loss: 1.130\n",
            "[3,   100] loss: 1.046\n",
            "[3,   200] loss: 1.025\n",
            "[3,   300] loss: 0.987\n",
            "[4,   100] loss: 0.931\n",
            "[4,   200] loss: 0.922\n",
            "[4,   300] loss: 0.905\n",
            "[5,   100] loss: 0.841\n",
            "[5,   200] loss: 0.826\n",
            "[5,   300] loss: 0.830\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UGng_Fyl9ui",
        "colab_type": "code",
        "outputId": "17ba9723-1497-4612-c8c9-b24e2e751326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test(cifar_net, testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: 0.0\n",
            "\n",
            "Test set: Accuracy: 6922/10000 (69%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DHUmpTnowio",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 shuffling의 효과\n",
        "무작위 sampling을 해준다.\n",
        "> 학습의 방해를 줄이기 위해 순서 패턴을 지운다.\n",
        "\n",
        "같은 데이터를 반복해서 학습하게 되면 그 순서 패턴을 학습하게 되는 문제가 발생한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpLd3Csgm1DL",
        "colab_type": "code",
        "outputId": "2d69d6bb-8ee2-48c5-a204-b07c285c6b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print('==> Preparing data...')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DM5TA0Rq2Xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_net = DiyCNN().to(device)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYTuNiMTrGXC",
        "colab_type": "code",
        "outputId": "4fb485fe-e19b-4f8b-c8e1-525bd2693098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "train_network(cifar_net, optimizer, trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.706\n",
            "[1,   200] loss: 1.467\n",
            "[1,   300] loss: 1.355\n",
            "[2,   100] loss: 1.197\n",
            "[2,   200] loss: 1.141\n",
            "[2,   300] loss: 1.098\n",
            "[3,   100] loss: 1.035\n",
            "[3,   200] loss: 1.003\n",
            "[3,   300] loss: 0.987\n",
            "[4,   100] loss: 0.939\n",
            "[4,   200] loss: 0.920\n",
            "[4,   300] loss: 0.905\n",
            "[5,   100] loss: 0.858\n",
            "[5,   200] loss: 0.844\n",
            "[5,   300] loss: 0.838\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dipNsdSdrLGy",
        "colab_type": "code",
        "outputId": "78dc731e-1799-4426-a01d-5834dcf3b4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test(cifar_net, testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: 0.0\n",
            "\n",
            "Test set: Accuracy: 7150/10000 (72%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YERD232ssvwW",
        "colab_type": "text"
      },
      "source": [
        "### Learning rate scheduler를 도입합니다. \n",
        "MultiStepLR(optimizer, milestones=[a,b], gamma = c)\n",
        "\n",
        "lr = optimizer의 lr (epoch < a)\n",
        "\n",
        "lr = lr\\*gamma (a <= epoch < b)\n",
        "\n",
        "lr = lr\\*gamma(b <= epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sQOYkVts1Tc",
        "colab_type": "text"
      },
      "source": [
        "기존의 설정으로 돌려줍니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soxQ7VW4rTeD",
        "colab_type": "code",
        "outputId": "4765a948-f7af-465b-bcf5-f90e832d75bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n",
        "    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "])\n",
        "\n",
        "\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "])\n",
        "\n",
        "# 데이터 로딩\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JNtO8IMsPhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DiyCNN, self).__init__()\n",
        "    layers = []\n",
        "\n",
        "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
        "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(128)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(256)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(512)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.AdaptiveAvgPool2d(1)]\n",
        "    \n",
        "    layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n",
        "    \n",
        "    self.main = nn.Sequential(*layers)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.main(x).squeeze(3).squeeze(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDy0oBRXsSHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network2(net, optimizer, trainloader, scheduler, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        \n",
        "        for i, data in enumerate(trainloader):\n",
        "            inputs, labels = data\n",
        "            \n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            if (i+1) % 100 == 0:\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                     (epoch+1, i + 1, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "#                 print('learning rate : ', optimizer.param_groups[0]['lr'])\n",
        "                \n",
        "        scheduler.step()\n",
        "        \n",
        "    print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znqgN3N6uAqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "scheduler = MultiStepLR(optimizer, milestones=[2,4], gamma=0.5)\n",
        "cifar_net = DiyCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=0.01)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[2,4], gamma=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq5z3GSuwYMq",
        "colab_type": "code",
        "outputId": "0bf0018e-a108-438d-d01b-c09e49b6e554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        }
      },
      "source": [
        "train_network2(cifar_net, optimizer, trainloader, scheduler,epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.843\n",
            "learning rate :  0.01\n",
            "[1,   200] loss: 1.565\n",
            "learning rate :  0.01\n",
            "[1,   300] loss: 1.433\n",
            "learning rate :  0.01\n",
            "[2,   100] loss: 1.275\n",
            "learning rate :  0.01\n",
            "[2,   200] loss: 1.209\n",
            "learning rate :  0.01\n",
            "[2,   300] loss: 1.163\n",
            "learning rate :  0.01\n",
            "[3,   100] loss: 1.003\n",
            "learning rate :  0.005\n",
            "[3,   200] loss: 0.960\n",
            "learning rate :  0.005\n",
            "[3,   300] loss: 0.945\n",
            "learning rate :  0.005\n",
            "[4,   100] loss: 0.911\n",
            "learning rate :  0.005\n",
            "[4,   200] loss: 0.884\n",
            "learning rate :  0.005\n",
            "[4,   300] loss: 0.853\n",
            "learning rate :  0.005\n",
            "[5,   100] loss: 0.788\n",
            "learning rate :  0.0025\n",
            "[5,   200] loss: 0.784\n",
            "learning rate :  0.0025\n",
            "[5,   300] loss: 0.769\n",
            "learning rate :  0.0025\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpKY54YV116D",
        "colab_type": "code",
        "outputId": "d06fa672-d602-45a5-9d51-454a40261e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test(cifar_net, testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: 0.0\n",
            "\n",
            "Test set: Accuracy: 7451/10000 (75%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6kYgQg55nz8",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained 모형 가지고 와서 성능 확인하기(Transfer Learning 관점)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq08djvd3PV1",
        "colab_type": "code",
        "outputId": "74330072-2640-4539-f2f2-676079843055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "import torchvision.models as models\n",
        "# 기존에 만들어진 vgg network 을 이미지넷 데이터에 트레이닝해둔\n",
        "# 파라미터를 그대로 받아온다.\n",
        "vgg_model = models.vgg19_bn(pretrained=True).to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/checkpoints/vgg19_bn-c79401a0.pth\n",
            "100%|██████████| 574769405/574769405 [00:04<00:00, 129129215.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0AOPolQ6YHg",
        "colab_type": "code",
        "outputId": "0f6306d0-c533-429e-960a-c226e63a0ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vgg_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace)\n",
              "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (25): ReLU(inplace)\n",
              "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace)\n",
              "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (35): ReLU(inplace)\n",
              "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (38): ReLU(inplace)\n",
              "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace)\n",
              "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (45): ReLU(inplace)\n",
              "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (48): ReLU(inplace)\n",
              "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (51): ReLU(inplace)\n",
              "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace)\n",
              "    (2): Dropout(p=0.5)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace)\n",
              "    (5): Dropout(p=0.5)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYhLhojN6n-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "    def __init__(self, vgg_model):\n",
        "        super(DiyCNN, self).__init__()\n",
        "        # 미리 학습된 vgg_model의 features에 있는 레이어들을 가져와서 붙여준다.\n",
        "        self.pre_trained = nn.Sequential(\n",
        "            *list(vgg_model.features.children()))\n",
        "        \n",
        "         # 기존에는 이미지넷에 학습되어있기 때문에, \n",
        "         # 이를 cifar-10 데이터셋용으로 바꿔줄 필요가 있다. \n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.pre_trained(x)\n",
        "        out = out.squeeze()\n",
        "        out = self.mlp(out)\n",
        "        return out\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdJ0FQQo8dKv",
        "colab_type": "code",
        "outputId": "aaa30180-ef39-41a4-ac7c-c019a44aae06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "cifar_net = DiyCNN(vgg_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr)\n",
        "\n",
        "print('[info] number of model parameter - %d'%(count_parameters(cifar_net)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.parameters() =  <generator object Module.parameters at 0x7fe7d82c90a0>\n",
            "[info] number of model parameter - 20365002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5U1kriP8uAK",
        "colab_type": "code",
        "outputId": "55bcdfaa-68b0-42aa-dcf8-e6c81000f952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "train_network(cifar_net, optimizer, trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.307\n",
            "[1,   200] loss: 0.949\n",
            "[1,   300] loss: 0.830\n",
            "[2,   100] loss: 0.684\n",
            "[2,   200] loss: 0.648\n",
            "[2,   300] loss: 0.627\n",
            "[3,   100] loss: 0.542\n",
            "[3,   200] loss: 0.531\n",
            "[3,   300] loss: 0.519\n",
            "[4,   100] loss: 0.470\n",
            "[4,   200] loss: 0.462\n",
            "[4,   300] loss: 0.460\n",
            "[5,   100] loss: 0.410\n",
            "[5,   200] loss: 0.421\n",
            "[5,   300] loss: 0.402\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMoe8rG9849z",
        "colab_type": "code",
        "outputId": "7376ecf8-fe21-4d2d-eced-0eede4d8ae86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "test(cifar_net, testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: 0.0\n",
            "\n",
            "Test set: Accuracy: 8563/10000 (86%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhJ6qcrd9EZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}