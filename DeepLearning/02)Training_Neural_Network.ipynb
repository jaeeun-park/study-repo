{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Neural_Network",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4MCjs3xUvr4",
        "colab_type": "text"
      },
      "source": [
        "### 일련의 과정을 따라서 만든다.\n",
        "1. 딥러닝 생성\n",
        "    - nn.Module을 상속했을 때 foward를 정의하면 backward를 자동적으로 만들어준다.\n",
        "2. 데이터 전처리\n",
        "3. DataLoader에 전처리한 데이터를 넣어준다.\n",
        "    - 데이터를 접근할 수 있는 권한을 가지면서 sampling한 minibatch를 제공해준다.\n",
        "    - iter() 형태로 만들어준다.\n",
        "4. for문 <- training(epoch 수만큼)\n",
        "    1. fowarding\n",
        "    2. loss: costfunc, objecfunc\n",
        "    3. backpropagation(backward)\n",
        "    4. update\n",
        "5. evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxfYGQhpUpgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn # neural network (nn)\n",
        "import torch.nn.functional as F # activation convolution function 뉴럴 네트워크를 위한 함수들이 정의 되어있는 모듈이다.\n",
        "import torchvision # 이미지 관련 처리, Pretrained Model 관련된 모듈이다.\n",
        "import torchvision.datasets as vision_dsets # 이미 주어진 데이터셋 사용\n",
        "import torchvision.transforms as T # 이미지 처리(Vision) 관련된 transformation이 정의 되어있는 모듈(normalization)\n",
        "import torch.optim as optim # optimizer들이 정의되어있는 모듈\n",
        "from torch.utils import data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5p7Ht7oWNZP",
        "colab_type": "text"
      },
      "source": [
        "## MNIST Feed-forward Neural Network\n",
        "\n",
        "### Data Loader 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY8Au9OsWLK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MNIST_DATA(root='./', train=True, transfomrs=None, download=True, batch_size=32, num_worker=1):\n",
        "    print('[+] Get the MNIST DATA')\n",
        "\n",
        "    mnist_train = vision_dsets.MNIST(root=root, # 데이터 저장 위치\n",
        "                                     train=True, # train 데이터인지 아닌지\n",
        "                                     transform=T.ToTensor(), # 데이터 전처리 여기서는 pytorch가 사용할 수 있는 형태인 Tensor형태로 변환해주는 작업\n",
        "                                     download=True) # 데이터를 다운로드 할지 여부\n",
        "    mnist_test = vision_dsets.MNIST(root=root,\n",
        "                                   train=False, # test 데이터를 가져온다.\n",
        "                                   transform=T.ToTensor(),\n",
        "                                   download=True)\n",
        "    \n",
        "    \"\"\"\n",
        "    DataLoader는 데이터와 batch size 정보를 바탕으로 매 iteration 마다 주어진 데이터를 원하는 batch size 만큼 반환해주는 iterator다.\n",
        "    batch size는 2의 배수로 저장하는 것이 좋다.\n",
        "    무조건 크다고 좋은것이 아니다. gpu memory size 고려해야 한다.\n",
        "    \"\"\"\n",
        "    trainLoader = data.DataLoader(dataset=mnist_train, # 어떤 데이터를 제공할건지\n",
        "                                  batch_size=batch_size, # 배치 사이즈\n",
        "                                  shuffle=True, # Train의 경우 shuffling을 해준다. True로하면 매 epoch마다 셔플링해서 순서를 학습하는 것을 방지\n",
        "                                  num_workers=1) # 데이터를 로드하는데 worker를 얼마나 추가하겠는가?\n",
        "    testLoader = data.DataLoader(dataset=mnist_test,\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=False, # test는 shuffling이 필요하지 않다.\n",
        "                                 num_workers=1)\n",
        "    \n",
        "    print('[+] Finished loading data & Preprocessing')\n",
        "    return mnist_train, mnist_test, trainLoader, testLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVNYyf0QYvML",
        "colab_type": "code",
        "outputId": "9a1fc21f-3aee-488a-aeb6-9509e5802b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "trainDataset, testDataset, trainLoader, testLoader = MNIST_DATA(batch_size=32)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[+] Get the MNIST DATA\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 21422860.39it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 315144.56it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5298643.90it/s]                           \n",
            "8192it [00:00, 130966.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "[+] Finished loading data & Preprocessing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGVApudRZVwk",
        "colab_type": "text"
      },
      "source": [
        "### Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixn0eM7cY6Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network(net, optimizer, trainloader, epochs=5):\n",
        "    for epoch in range(epochs): # epochs만큼 반복\n",
        "\n",
        "        running_loss = 0.0 # running loss를 저장할 변수\n",
        "        for i, data in enumerate(trainloader):\n",
        "            inputs, labels = data # DataLoader iterator의 반환값은 (input_data, label)형태이다. unpacking 해준다\n",
        "            inputs = inputs.cuda() # gou에 데이터를 올린다.\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            # 현재 backprop을 계산하기 위해서 기존의 저장된 activation buffer를 비운다.\n",
        "            optimizer.zero_grad()\n",
        "            # 위의 작업을 안해주면 메모리가 터지므로 기존의 gradient를 날려줘야한다.\n",
        "\n",
        "            outputs = net(inputs) # network로부터 inputs에 대한 outputs를 얻는다. \n",
        "            # loss function에 주어진 target과 output의 score를 계산하여 반환한다.\n",
        "            loss = criterion(outputs, labels)\n",
        "            # loss를 이용해 backpropagation을 진행한다.\n",
        "            loss.backward()\n",
        "            # backprop을 바탕으로 optimizer가 gradient descenting을 수행한다. -> weight 조정한다.\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 500 == 499: # print every 2000 mini-batch\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch+1, i+1, running_loss/500))\n",
        "                running_loss=0.0\n",
        "    \n",
        "    print('Finished Trainig')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjiqqu5GdcqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, testloader):\n",
        "    model.eval() # batchnorm, dropout을 사용하는데 test이므로 eval 모드로 사용하겠다고 선언\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in testloader:\n",
        "        # gpu로 올려준다.\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        outputs = model(data)\n",
        "        pred = outputs.max(1, keepdim=True)[1] # get the index of max\n",
        "        # max인 이유 -> 가장 높은 score 가진 것으로 예측한것임\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item() # 정답 데이터의 갯수를 반환\n",
        "\n",
        "    test_loss /= len(testloader.dataset)\n",
        "    print('\\n Test set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        correct, len(testloader.dataset), \n",
        "        100. * correct / len(testloader.dataset)\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzbVlKd0e58q",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network + Activation Function "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDb470soe-LJ",
        "colab_type": "text"
      },
      "source": [
        "### 간단한 Neural Network를 만들어보자.(1)\n",
        "특징: 2개의 Layer를 가지는 Neural Network  \n",
        "Layer1 = input: 28*28, output: 30 + Activation Function = Sigmoid  \n",
        "Layer2 = input: 30, output:10 -> 모델의 클래스 개수(0~9)가 output 수  \n",
        "Cross Entropy Loss, SGD optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqhuG_RMe3wX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "\n",
        "        self.fc0 = nn.Linear(28*28, 30)\n",
        "        self.fc1 = nn.Linear(30,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28) # batchsize, inputsize 로 reshape\n",
        "        x = F.sigmoid(self.fc0(x)) # activation function 수행\n",
        "        x = self.fc1(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13S7O37iftYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda() # 정의한 모델을 인스턴스화 하고 gpu에 올린다\n",
        "criterion = nn.CrossEntropyLoss() # loss function 정의 CrossEntropyLoss 사용 -> softmax있으므로 logit 값을 줘야한다.\n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fp4AR5ygsql",
        "colab_type": "code",
        "outputId": "82b3ecc8-1aa1-4e23-aea9-a5d72f4e69e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "train_network(mnist_net, optimizer, trainLoader)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.353\n",
            "[1,  1000] loss: 2.310\n",
            "[1,  1500] loss: 2.286\n",
            "[2,   500] loss: 2.259\n",
            "[2,  1000] loss: 2.247\n",
            "[2,  1500] loss: 2.234\n",
            "[3,   500] loss: 2.212\n",
            "[3,  1000] loss: 2.198\n",
            "[3,  1500] loss: 2.185\n",
            "[4,   500] loss: 2.158\n",
            "[4,  1000] loss: 2.143\n",
            "[4,  1500] loss: 2.125\n",
            "[5,   500] loss: 2.093\n",
            "[5,  1000] loss: 2.073\n",
            "[5,  1500] loss: 2.053\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42twVl5mgwo1",
        "colab_type": "code",
        "outputId": "9f36231e-707c-4aa4-9220-a4f706ec63ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 6394/10000 (64%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArQmYBoJi2a8",
        "colab_type": "text"
      },
      "source": [
        "### 간단한 Neural Network를 만들어보자.(2)\n",
        "특징: 2개의 Layer를 가지는 Neural Network  \n",
        "Layer1 = input: 28*28, output: 30 + Activation Function = tanh   \n",
        "Layer2 = input: 30, output:10 -> 모델의 클래스 개수(0~9)가 output 수  \n",
        "Cross Entropy Loss, SGD optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w3TYoJli5xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__() # nn.Module 생성자 호출 Q) 왜 필요할까요?\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,30)\n",
        "        self.fc1 = nn.Linear(30, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,28*28) # x.view함수는 주어진 인자의 크기로 해당 데이터의 크기를 반환합니다. 즉, (Batch_size,28,28) --> (Batch_size,28*28)로 변환합니다.\n",
        "        x = F.tanh(self.fc0(x)) # 28*28 -> 30 -> Activation function 을 수행합니다.\n",
        "        x = self.fc1(x)  # 30 -> 10 으로 10개의 Class에 대한 logit 값을 호출합니다. \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84WxprpZjvrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFPJke8Rj7E1",
        "colab_type": "code",
        "outputId": "160b2927-9771-4443-ddc9-990ed6d5ca0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "train_network(mnist_net, optimizer, trainLoader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.221\n",
            "[1,  1000] loss: 2.059\n",
            "[1,  1500] loss: 1.907\n",
            "[2,   500] loss: 1.652\n",
            "[2,  1000] loss: 1.529\n",
            "[2,  1500] loss: 1.407\n",
            "[3,   500] loss: 1.241\n",
            "[3,  1000] loss: 1.152\n",
            "[3,  1500] loss: 1.078\n",
            "[4,   500] loss: 0.979\n",
            "[4,  1000] loss: 0.936\n",
            "[4,  1500] loss: 0.887\n",
            "[5,   500] loss: 0.827\n",
            "[5,  1000] loss: 0.790\n",
            "[5,  1500] loss: 0.755\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpMLmNtBj-TY",
        "colab_type": "code",
        "outputId": "b77b21f1-0a64-4266-8757-32069535e754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 8485/10000 (85%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEu7ycfMl9GO",
        "colab_type": "text"
      },
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (3)\n",
        "특징 : 2개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 30 + Activation Fucntion - Relu\n",
        "\n",
        "Layer 2 - input: 30 output:10\n",
        "\n",
        "Cross Entropy Loss  + SGD optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBQFJxQMl5ZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "\n",
        "        self.fc0 = nn.Linear(28*28, 30)\n",
        "        self.fc1 = nn.Linear(30, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc0(x))\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9wjU38NmWW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskmW3l8mjYN",
        "colab_type": "code",
        "outputId": "88fa5bc0-c462-44cd-f6d1-091cd78b1e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "train_network(mnist_net, optimizer, trainLoader)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.282\n",
            "[1,  1000] loss: 2.209\n",
            "[1,  1500] loss: 2.118\n",
            "[2,   500] loss: 1.913\n",
            "[2,  1000] loss: 1.768\n",
            "[2,  1500] loss: 1.612\n",
            "[3,   500] loss: 1.347\n",
            "[3,  1000] loss: 1.209\n",
            "[3,  1500] loss: 1.096\n",
            "[4,   500] loss: 0.939\n",
            "[4,  1000] loss: 0.889\n",
            "[4,  1500] loss: 0.825\n",
            "[5,   500] loss: 0.746\n",
            "[5,  1000] loss: 0.712\n",
            "[5,  1500] loss: 0.680\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRlnSCmymm5t",
        "colab_type": "code",
        "outputId": "ea6eca9d-2e74-489e-f1e6-3a69be248bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 8573/10000 (86%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA7xDNIfnR4B",
        "colab_type": "text"
      },
      "source": [
        "성능 차이가 나는 이유\n",
        "1. sigmoid(58%))\n",
        "    - not zero centered -> zigzag(느림)\n",
        "    - saturated -> 제대로 학습이 안됨\n",
        "2. tanh(84%)\n",
        "    - zero centered\n",
        "    - saturated -> 제대로 학습이 안됨\n",
        "3. relu(86%)\n",
        "    - 계산 비용이 작다\n",
        "    - 양수 부분에서 not saturated -> good"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTsVhxXLn57J",
        "colab_type": "text"
      },
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (4) \n",
        "특징 : 3개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 40 + Activation Fucntion - sigmoid \n",
        "\n",
        "Layer 2 - input: 40 output: 30\n",
        "\n",
        "Layer 3 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + SGD optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUvEwOKvnJ-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "\n",
        "        self.fc0 = nn.Linear(28*28, 40)\n",
        "        self.fc1 = nn.Linear(40, 30)\n",
        "        self.fc2 = nn.Linear(30,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.sigmoid(self.fc0(x))\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXOdonl2obJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt2FmLHAokPF",
        "colab_type": "code",
        "outputId": "bca9acb3-71ed-4390-ee64-9e9ddc6c7580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "train_network(mnist_net, optimizer, trainLoader)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.346\n",
            "[1,  1000] loss: 2.322\n",
            "[1,  1500] loss: 2.310\n",
            "[2,   500] loss: 2.301\n",
            "[2,  1000] loss: 2.300\n",
            "[2,  1500] loss: 2.299\n",
            "[3,   500] loss: 2.299\n",
            "[3,  1000] loss: 2.299\n",
            "[3,  1500] loss: 2.298\n",
            "[4,   500] loss: 2.298\n",
            "[4,  1000] loss: 2.297\n",
            "[4,  1500] loss: 2.297\n",
            "[5,   500] loss: 2.296\n",
            "[5,  1000] loss: 2.296\n",
            "[5,  1500] loss: 2.297\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtpVNJPHoq8D",
        "colab_type": "code",
        "outputId": "83fd71ce-0645-4b72-b16c-d74d6ff1fba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 1135/10000 (11%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeUcWlt9o-IE",
        "colab_type": "text"
      },
      "source": [
        "### Q) 왜 학습이 잘 안될까?\n",
        " - 시그모이드는 레이어가 쌓이면 학습이 잘 안된다.\n",
        " - staturated 되서 gradient = 0 이 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnARhx06pNBp",
        "colab_type": "text"
      },
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (5) \n",
        "특징 : 3개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 40 + Activation Fucntion - Relu \n",
        "\n",
        "Layer 2 - input: 40 output: 30\n",
        "\n",
        "Layer 3 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + SGD optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-vcFWZYo6r_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        self.fc0 = nn.Linear(28*28, 40)\n",
        "        self.fc1 = nn.Linear(40,30)\n",
        "        self.fc2 = nn.Linear(30,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc0(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAjlA_gpqbXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(mnist_net.parameters(), lr = 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5GJlo4Uqn5H",
        "colab_type": "code",
        "outputId": "5c43ef14-4503-4fea-b9d8-74cf2473ff93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "train_network(mnist_net, optimizer, trainLoader)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 2.298\n",
            "[1,  1000] loss: 2.272\n",
            "[1,  1500] loss: 2.245\n",
            "[2,   500] loss: 2.184\n",
            "[2,  1000] loss: 2.138\n",
            "[2,  1500] loss: 2.086\n",
            "[3,   500] loss: 1.956\n",
            "[3,  1000] loss: 1.868\n",
            "[3,  1500] loss: 1.757\n",
            "[4,   500] loss: 1.546\n",
            "[4,  1000] loss: 1.409\n",
            "[4,  1500] loss: 1.300\n",
            "[5,   500] loss: 1.118\n",
            "[5,  1000] loss: 1.042\n",
            "[5,  1500] loss: 0.978\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGtLNOgQqr1n",
        "colab_type": "code",
        "outputId": "192d0501-1fa4-422c-ae66-a6dc6eae6de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 7498/10000 (75%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISvRzA5_rLFw",
        "colab_type": "text"
      },
      "source": [
        "(4) 와의 차이: relu는 음수이면 0 양수이면 x인 함수 -> gradient saturate가 없다.  \n",
        "(3) 과의 차이: SGD가 local minima & saddle point에서 문제가 발생한다. -> optimizer를 바꿔준다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyqAdRRfrc5D",
        "colab_type": "text"
      },
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (6) \n",
        "특징 : 3개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 40 + Activation Fucntion - Relu \n",
        "\n",
        "Layer 2 - input: 40 output: 30\n",
        "\n",
        "Layer 3 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + **Adam** optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2Lo3A_vq8j0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,40) #Layer 1 \n",
        "        self.fc1 = nn.Linear(40, 30) # Layer 2\n",
        "        self.fc2 = nn.Linear(30, 10) # Layer 3\n",
        "\n",
        "    def forward(self, x):\n",
        "       \n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.relu(self.fc0(x)) # Layer 1\n",
        "        x = F.relu(self.fc1(x)) # Layer 2\n",
        "        x = self.fc2(x) # Layer 3 \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsKpTxCQsgkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimzier = optim.Adam(mnist_net.parameters(), lr=0.001)\n",
        "# Adam = momentum + Ada"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VZ73s1mstCd",
        "colab_type": "code",
        "outputId": "d46402b2-30e6-45cd-89a9-76fdf4b2a564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "train_network(mnist_net, optimzier, trainLoader)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.665\n",
            "[1,  1000] loss: 0.316\n",
            "[1,  1500] loss: 0.276\n",
            "[2,   500] loss: 0.213\n",
            "[2,  1000] loss: 0.195\n",
            "[2,  1500] loss: 0.178\n",
            "[3,   500] loss: 0.150\n",
            "[3,  1000] loss: 0.148\n",
            "[3,  1500] loss: 0.137\n",
            "[4,   500] loss: 0.116\n",
            "[4,  1000] loss: 0.126\n",
            "[4,  1500] loss: 0.121\n",
            "[5,   500] loss: 0.106\n",
            "[5,  1000] loss: 0.098\n",
            "[5,  1500] loss: 0.106\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpphUbcyswf2",
        "colab_type": "code",
        "outputId": "2a297b07-55f4-4714-a9a6-c6ccd2dc8be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 9640/10000 (96%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIIZNESitPIA",
        "colab_type": "text"
      },
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (7) Layer 를 줄여볼까요? \n",
        "특징 : 2개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 30 + Activation Fucntion - Relu \n",
        "\n",
        "Layer 2 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + **Adam** optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82zRMDaUsyop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc0 = nn.Linear(28*28,30) #Layer 1 \n",
        "        self.fc1 = nn.Linear(30, 10) # Layer 3\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.relu(self.fc0(x)) # Layer 1\n",
        "        x = self.fc1(x) # Layer 3 \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Hp5uZhtVPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimzier = optim.Adam(mnist_net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RySSNjPPtYV7",
        "colab_type": "code",
        "outputId": "81e99b73-2660-410b-83f1-018416090b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "train_network(mnist_net, optimzier, trainLoader)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.680\n",
            "[1,  1000] loss: 0.332\n",
            "[1,  1500] loss: 0.298\n",
            "[2,   500] loss: 0.246\n",
            "[2,  1000] loss: 0.224\n",
            "[2,  1500] loss: 0.207\n",
            "[3,   500] loss: 0.180\n",
            "[3,  1000] loss: 0.169\n",
            "[3,  1500] loss: 0.175\n",
            "[4,   500] loss: 0.148\n",
            "[4,  1000] loss: 0.153\n",
            "[4,  1500] loss: 0.150\n",
            "[5,   500] loss: 0.136\n",
            "[5,  1000] loss: 0.127\n",
            "[5,  1500] loss: 0.125\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee8VQKsktaGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "021afd65-ec9d-4e79-99d7-c075a56aa5de"
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 9582/10000 (96%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms5XomwmtsIi",
        "colab_type": "text"
      },
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (7) Batch Norm 을 줘 볼까요?\n",
        "특징 : 2개의 Layer를 가지는 Neural Network \n",
        "<구성>  \n",
        "Layer 1 - input:28*28 , output : 30 + Activation Fucntion - Relu  + Batch Norm\n",
        "\n",
        "Layer 2 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + **Adam** optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksPtuDFLYtag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "\n",
        "        self.fc0 = nn.Linear(28*28, 30)\n",
        "        self.bn0 = nn.BatchNorm1d(30)\n",
        "        self.fc1 = nn.Linear(30, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.bn0(self.fc0(x)))\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOhaQ1xJZK7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqA94NPhZVUF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "61fac736-4300-4145-d045-2492e5cbee9f"
      },
      "source": [
        "train_network(mnist_net, optimizer, trainLoader)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.720\n",
            "[1,  1000] loss: 0.334\n",
            "[1,  1500] loss: 0.285\n",
            "[2,   500] loss: 0.225\n",
            "[2,  1000] loss: 0.224\n",
            "[2,  1500] loss: 0.208\n",
            "[3,   500] loss: 0.181\n",
            "[3,  1000] loss: 0.182\n",
            "[3,  1500] loss: 0.182\n",
            "[4,   500] loss: 0.156\n",
            "[4,  1000] loss: 0.156\n",
            "[4,  1500] loss: 0.164\n",
            "[5,   500] loss: 0.139\n",
            "[5,  1000] loss: 0.138\n",
            "[5,  1500] loss: 0.145\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utT17BapZafC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "db865579-a9ee-4d07-b8a9-833611204cf6"
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 9641/10000 (96%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozsYNOuGZ811",
        "colab_type": "text"
      },
      "source": [
        "### 간단한 Neural Network 를 만들어 봅시다. (8) 더 깊은 레이어에 Batch Norm 을 줘 볼까요?\n",
        "특징 : 2개의 Layer를 가지는 Neural Network\n",
        "\n",
        "<구성>  \n",
        "\n",
        "Layer 1 - input:28*28 , output : 40 + Activation Fucntion - Relu + BatchNorm\n",
        "\n",
        "Layer 2 - input: 40 output: 30 + Activation Fucntion - Relu  + BatchNorm\n",
        "\n",
        "Layer 3 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss  + **Adam** optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMA7QOzGZpY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        self.fc0 = nn.Linear(28*28, 40)\n",
        "        self.bn0 = nn.BatchNorm1d(40)\n",
        "        self.fc1 = nn.Linear(40, 30)\n",
        "        self.bn1 = nn.BatchNorm1d(30)\n",
        "        self.fc2 = nn.Linear(30, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,28*28)\n",
        "        x = F.relu(self.bn0(self.fc0(x)))\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUviAXk-aj7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwqRy9MQaunZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "d8e7d025-a6d8-4824-d41f-d82cb4ee07d5"
      },
      "source": [
        "train_network(mnist_net, optimizer, trainLoader)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.676\n",
            "[1,  1000] loss: 0.269\n",
            "[1,  1500] loss: 0.227\n",
            "[2,   500] loss: 0.173\n",
            "[2,  1000] loss: 0.162\n",
            "[2,  1500] loss: 0.140\n",
            "[3,   500] loss: 0.121\n",
            "[3,  1000] loss: 0.122\n",
            "[3,  1500] loss: 0.126\n",
            "[4,   500] loss: 0.109\n",
            "[4,  1000] loss: 0.107\n",
            "[4,  1500] loss: 0.112\n",
            "[5,   500] loss: 0.093\n",
            "[5,  1000] loss: 0.093\n",
            "[5,  1500] loss: 0.104\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sWZi4Vpa1BP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "8f220898-572d-42a2-ae1b-993d4f73fdbe"
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 9744/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls2zhoe6bNKI",
        "colab_type": "text"
      },
      "source": [
        "깊은 Neural Network에서 BatchNorm을 사용하면 정확도가 증가한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHcWhH0Ibp9R",
        "colab_type": "text"
      },
      "source": [
        "## Practical Guide Pytorch nn.Sequential "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-G-NLOcbq33",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "x = F.relu(self.bn0(self.fc0(x)))\n",
        "x = F.relu(self.bn1(self.fc1(x)))\n",
        "```\n",
        "너무 복잡하지 않나요?  그냥 x = self.fc(x) 쉽게 해버리면 안 될까요?\n",
        "\n",
        "Solution : nn.Sequential + 자매품 nn.ModuList\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJAvUWuQbqbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "\n",
        "        layer_list = []\n",
        "        layer_list.append(nn.Linear(28*28, 40)) # Layer1\n",
        "        layer_list.append(nn.BatchNorm1d(40)) # BatchNorm1(after FC, Conv / before nonlinearity)\n",
        "        layer_list.append(nn.ReLU())\n",
        "        layer_list.append(nn.Linear(40,30)) # Layer2\n",
        "        layer_list.append(nn.BatchNorm1d(30)) # BatchNorm2\n",
        "        layer_list.append(nn.ReLU())\n",
        "        layer_list.append(nn.Linear(30,10)) # Layer3\n",
        "        self.net = nn.Sequential(*layer_list)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.net(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIjV6uQ4cSqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aESBq2-Mcbua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "31f1c50c-a8e5-4c4e-c2b0-43e661f580e4"
      },
      "source": [
        "train_network(mnist_net, optimizer, trainLoader)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.670\n",
            "[1,  1000] loss: 0.274\n",
            "[1,  1500] loss: 0.211\n",
            "[2,   500] loss: 0.157\n",
            "[2,  1000] loss: 0.159\n",
            "[2,  1500] loss: 0.161\n",
            "[3,   500] loss: 0.134\n",
            "[3,  1000] loss: 0.131\n",
            "[3,  1500] loss: 0.129\n",
            "[4,   500] loss: 0.108\n",
            "[4,  1000] loss: 0.115\n",
            "[4,  1500] loss: 0.113\n",
            "[5,   500] loss: 0.095\n",
            "[5,  1000] loss: 0.103\n",
            "[5,  1500] loss: 0.105\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SysdoT-hcfjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "47e0a4c8-ff69-4838-f0f4-8e72dd238763"
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 9709/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnKsh07icmxd",
        "colab_type": "text"
      },
      "source": [
        "#### 연습해 봅시다 ! \n",
        "\n",
        "특징 : 2개의 Layer를 가지는 Neural Network <구성>\n",
        "\n",
        "Layer 1 - input:28*28 , output : 30 + Activation Fucntion - Relu + Batch Norm\n",
        "\n",
        "Layer 2 - input: 30 output : 10\n",
        "\n",
        "Cross Entropy Loss + Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G8VKt0gcg3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "\n",
        "        layer_list = []\n",
        "        layer_list.append(nn.Linear(28*28, 30))\n",
        "        layer_list.append(nn.BatchNorm1d(30))\n",
        "        layer_list.append(nn.ReLU())\n",
        "        layer_list.append(nn.Linear(30,10))\n",
        "        self.net = nn.Sequential(*layer_list)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh6SP0TkcqPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GIbtzvWeyO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "35a79505-fd88-4d94-b5c3-06b5b9cb02db"
      },
      "source": [
        "train_network(mnist_net, optimizer, trainLoader)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.708\n",
            "[1,  1000] loss: 0.347\n",
            "[1,  1500] loss: 0.290\n",
            "[2,   500] loss: 0.224\n",
            "[2,  1000] loss: 0.221\n",
            "[2,  1500] loss: 0.205\n",
            "[3,   500] loss: 0.176\n",
            "[3,  1000] loss: 0.168\n",
            "[3,  1500] loss: 0.167\n",
            "[4,   500] loss: 0.143\n",
            "[4,  1000] loss: 0.147\n",
            "[4,  1500] loss: 0.161\n",
            "[5,   500] loss: 0.131\n",
            "[5,  1000] loss: 0.133\n",
            "[5,  1500] loss: 0.136\n",
            "Finished Trainig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8yFLAEQe3j8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "d5bd50c0-a7b4-4cbc-88a9-5924cd914ed6"
      },
      "source": [
        "test(mnist_net, testLoader)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test set: Accuracy: 9645/10000 (96%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NW3pv_4e5r8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}